#=========================== Filebeat inputs =============================
filebeat.inputs:

- type: log
  enabled: true

  # Glob based paths.
  paths:
    - 'C:\Logfiles\CLSLog-*'

  close_inactive: 90s
  harvester_limit: 1000
  scan_frequency: 1s
  symlinks: true
  clean_removed: true
  fields:
    _message_parser:
      type: grok
      pattern: '%{NOTSPACE:level:meta}\(%{NOTSPACE:flag:meta}\) \[%{NOTSPACE:machine:meta}\]%{BASE16NUM:process}\.%{BASE16NUM:thread}::%{NOTSPACE:timestamp:datetime:MM/dd/yyyy-HH:mm:ss.SSS}\.%{BASE16NUM:sequence-num} \(%{NOTSPACE:component:meta},%{NOTSPACE:source}\) (\[%{NOTSPACE:correlation-id}\])?%{SPACE}(?:[<>]+%{DATA:message-header}%{SPACE}|:Start-Line: )?%{GREEDYDATA:message}'
      subParsers:
        message:
          type: sip
          sortedFields: "call-id,user-agent"

  multiline.pattern: ^TL_
  multiline.negate: true
  multiline.match: after
  
#================================ Processors =====================================
# Drop metadata added by Filebeat to save bandwidth as it's unnecessary

processors:
  - add_locale: ~
  - rename:
      when:
        has_fields: ['fields._message_parser']
      fields:
        - from: "event.timezone"
          to: "fields._message_parser.defaultTimeZone"
  - rename:
      fields:
        - from: "agent.hostname"
          to: "hostname"
  - drop_fields:
      fields: ["host", "input", "ecs", "agent", "event"]

#==================== Elasticsearch template setting ==========================
setup.template:
  name: "logs"
  pattern: "logs"
  fields: "fields.yml"
  overwrite: true

#-------------------------- Elasticsearch output ------------------------------
output.elasticsearch:
  bulk_max_size: 3000
  worker: 30
  compression_level: 5
  hosts: "DASHBASE_URL:443"
  protocol: "https"
  ssl.verification_mode: "none"

#================================ Logging =====================================

# Available log levels are: error, warning, info, debug
logging.level: info
