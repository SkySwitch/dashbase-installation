rule_files:
  - dashbase-alerts/table.yml

tests:
  - interval: 1m
    input_series:
      - series: jvm_cpu_usage_percent{component='table',app='test',instance='myhost'}
        values: 91+0x10

    alert_rule_test:
      - eval_time: 10m
        alertname: table_cpu_high
        exp_alerts:
          - exp_labels:
              app: test
              instance: myhost
              severity: warning
            exp_annotations:
              description: "Table 'myhost' in 'test' is using 91% of CPU. Check if traffic is too high or unbalanced."

  - interval: 1m
    input_series:
      - series: dashbase_disk_available_bytes{app='test',instance='p1'}
        values: 499+0x5
      - series: dashbase_disk_available_bytes{app='test',instance='p2'}
        values: 599+0x5
      - series: dashbase_disk_total_bytes{app='test',instance='p1'}
        values: 10000+0x5
      - series: dashbase_disk_total_bytes{app='test',instance='p2'}
        values: 10000+0x5
    alert_rule_test:
      - eval_time: 5m
        alertname: table_free_disk_low
        exp_alerts:
          - exp_labels:
              app: test
              instance: p1
              severity: critical
            exp_annotations:
              description: "Table 'p1' in 'test' has only 4.99% free disk space. Check if retention parameters are correct."

  - interval: 1m
    input_series:
      - series: dashbase_index_event_parse_error{app='test',instance='p1'}
        values: 0+1x15
    alert_rule_test:
      - eval_time: 15m
        alertname: table_request_parse_errors_high
        exp_alerts:
          - exp_labels:
              app: test
              instance: p1
              severity: critical
            exp_annotations:
              description: "Table 'p1' in 'test' has request parse errors. Check if log harvester's configuration is correct."

  - interval: 1m
    input_series:
      - series: dashbase_parse_error_total{app='test',instance='p1'}
        values: 1000+60x15
      - series: dashbase_ingestion_events_total{app='test',instance='p1'}
        values: 1000+6000x15
      - series: dashbase_parse_error_total{app='test',instance='p2'}
        values: 1000+59x15
      - series: dashbase_ingestion_events_total{app='test',instance='p2'}
        values: 1000+6000x15
    alert_rule_test:
      - eval_time: 16m
        alertname: table_ingest_parse_errors_high
        exp_alerts:
          - exp_labels:
              app: test
              instance: p1
              severity: critical
            exp_annotations:
              description: "Table 'p1' in 'test' has 1% parse errors. Check if parser configuration is correct."

  - interval: 1m
    input_series:
      - series: dashbase_parse_skipped_total{app='test',instance='p1'}
        values: 1000+60x15
      - series: dashbase_ingestion_events_total{app='test',instance='p1'}
        values: 1000+6000x15
      - series: dashbase_parse_skipped_total{app='test',instance='p2'}
        values: 1000+59x15
      - series: dashbase_ingestion_events_total{app='test',instance='p2'}
        values: 1000+6000x15
    alert_rule_test:
      - eval_time: 16m
        alertname: table_ingest_parse_skipped_high
        exp_alerts:
          - exp_labels:
              app: test
              instance: p1
              severity: critical
            exp_annotations:
              description: "Table 'p1' in 'test' has 1% timestamp errors. Check if timestamp parser configuration is correct."

  - interval: 1m
    input_series:
      - series: dashbase_ingestion_bytes_total{app='test',table='filebeat',instance='p1'}
        values: 1000+0x10
      - series: dashbase_ingestion_bytes_total{app='test',table='filebeat',instance='p2'}
        values: 0+0x10
    alert_rule_test:
      - eval_time: 11m
        alertname: table_partition_no_ingestion
        exp_alerts:
          - exp_labels:
              app: test
              severity: critical
              table: filebeat
            exp_annotations:
              description: "One or more partitions in Table 'filebeat' in 'test' is not ingesting any data. Please check the status of each partition in the table."

  # table_partition_no_ingestion should not fire if table itself is not ingesting any data.
  - interval: 1m
    input_series:
      - series: dashbase_ingestion_bytes_total{app='test',table='filebeat',instance='p1'}
        values: 0+0x10
      - series: dashbase_ingestion_bytes_total{app='test',table='filebeat',instance='p2'}
        values: 0+0x10
    alert_rule_test:
      - eval_time: 11m
        alertname: table_partition_no_ingestion
        exp_alerts:

  # table_partition_no_ingestion should not fire if table itself is not ingesting any data.
  - interval: 1m
    input_series:
      - series: dashbase_invalid_timeslice_count{app='test',table='filebeat',instance='p1'}
        values: 0+10x10
    alert_rule_test:
      - eval_time: 11m
        alertname: table_invalid_segments
        exp_alerts:
          - exp_labels:
              app: test
              severity: critical
              table: filebeat
              instance: p1
            exp_annotations:
              description: "Table 'p1' in 'test' is producing invalid segments. Check the log and segment info files to figure out why."

  - interval: 1m
    input_series:
      - series: dashbase_indexer_full_latency_secs_sum{app='test', table='filebeat',instance='p0'}
        values: 0+7201x15
      - series: dashbase_indexer_full_latency_secs_count{app='test', table='filebeat',instance='p0'}
        values: 0+1x15
    alert_rule_test:
      - eval_time: 16m
        alertname: table_ingestion_delay_high
        exp_alerts:
          - exp_labels:
              app: test
              severity: warning
              table: filebeat
              instance: p0
            exp_annotations:
              description: "Table 'p0' in 'test' has ingestion delayed for more than 1 hour(7201 seconds). Check if indexing is working well."